{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5aa75378-35dc-4e70-9787-7c3eb9943551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f654167-fb59-4209-a786-a47c7ba59516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generated and saved as 'synthetic_customer_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Initialize Faker\n",
    "faker = Faker()\n",
    "\n",
    "# Generate synthetic dataset\n",
    "n_samples = 1000\n",
    "data = {\n",
    "    'Customer_ID': [faker.uuid4() for _ in range(n_samples)],\n",
    "    'Age': np.random.randint(18, 70, size=n_samples),\n",
    "    'Gender': np.random.choice(['Male', 'Female', 'Other'], size=n_samples),\n",
    "    'Annual_Income': np.random.uniform(15000, 120000, size=n_samples),\n",
    "    'Credit_Score': np.random.uniform(300, 850, size=n_samples),\n",
    "    'Transaction_Amount': np.random.uniform(10, 5000, size=n_samples),\n",
    "    'Purchase_Frequency': np.random.randint(1, 20, size=n_samples),\n",
    "    'Region': np.random.choice(['North', 'South', 'East', 'West'], size=n_samples),\n",
    "    'Customer_Satisfaction': np.random.choice([1, 2, 3, 4, 5], size=n_samples),\n",
    "    'Join_Date': [faker.date_this_decade() for _ in range(n_samples)]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Introduce inconsistencies\n",
    "df.loc[random.sample(range(n_samples), 50), 'Age'] = np.nan  # Missing values\n",
    "df.loc[random.sample(range(n_samples), 30), 'Annual_Income'] = np.nan\n",
    "df.loc[random.sample(range(n_samples), 5), 'Transaction_Amount'] = 10000  # Outliers\n",
    "df = pd.concat([df, df.iloc[0:10]])  # Duplicates\n",
    "\n",
    "# Save raw dataset\n",
    "df.to_csv('synthetic_customer_data.csv', index=False)\n",
    "print(\"Dataset generated and saved as 'synthetic_customer_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f69c9f0e-d2e0-46cd-b8b3-b4bfe8d5d627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed and saved as 'preprocessed_customer_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df_raw = pd.read_csv('synthetic_customer_data.csv')\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_raw['Age'] = imputer.fit_transform(df_raw[['Age']])\n",
    "df_raw['Annual_Income'] = imputer.fit_transform(df_raw[['Annual_Income']])\n",
    "\n",
    "# Drop duplicates\n",
    "df_cleaned = df_raw.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Handle outliers in Transaction_Amount\n",
    "df_cleaned.loc[df_cleaned['Transaction_Amount'] > 5000, 'Transaction_Amount'] = df_cleaned['Transaction_Amount'].median()\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_features = ['Gender', 'Region']\n",
    "df_encoded = pd.get_dummies(df_cleaned, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['Age', 'Annual_Income', 'Credit_Score', 'Transaction_Amount', 'Purchase_Frequency']\n",
    "df_encoded[numerical_features] = scaler.fit_transform(df_encoded[numerical_features].copy())\n",
    "\n",
    "# Discretize Age into bins\n",
    "discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "df_encoded['Age_Binned'] = discretizer.fit_transform(df_encoded[['Age']].copy())\n",
    "\n",
    "# Dimensionality reduction using PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_features = pca.fit_transform(df_encoded[numerical_features].copy())\n",
    "df_encoded.loc[:, 'PCA_1'] = pca_features[:, 0]\n",
    "df_encoded.loc[:, 'PCA_2'] = pca_features[:, 1]\n",
    "\n",
    "# Save preprocessed dataset\n",
    "df_encoded.to_csv('preprocessed_customer_data.csv', index=False)\n",
    "print(\"Preprocessing completed and saved as 'preprocessed_customer_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a24f305-a78d-4599-9496-d1045c27ef05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on Raw Data: 1476.6117937212434\n",
      "R-squared on Raw Data: -0.056488930992956154\n",
      "RMSE on Preprocessed Data: 0.9382753739804405\n",
      "R-squared on Preprocessed Data: 0.046337407293424504\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "df_raw = pd.read_csv('synthetic_customer_data.csv')\n",
    "df_preprocessed = pd.read_csv('preprocessed_customer_data.csv')\n",
    "\n",
    "# Minimal preprocessing for raw data\n",
    "df_raw['Age'] = df_raw['Age'].fillna(df_raw['Age'].mean())\n",
    "df_raw['Annual_Income'] = df_raw['Annual_Income'].fillna(df_raw['Annual_Income'].mean())\n",
    "df_raw = pd.get_dummies(df_raw, columns=['Gender', 'Region'], drop_first=True)\n",
    "\n",
    "# Raw data: Features and target\n",
    "X_raw = df_raw.drop(['Customer_ID', 'Transaction_Amount', 'Join_Date'], axis=1)\n",
    "y_raw = df_raw['Transaction_Amount']\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_raw, y_raw, test_size=0.2, random_state=42)\n",
    "model_raw = RandomForestRegressor(random_state=42)\n",
    "model_raw.fit(X_train_raw, y_train_raw)\n",
    "y_pred_raw = model_raw.predict(X_test_raw)\n",
    "\n",
    "# Metrics for raw data\n",
    "rmse_raw = np.sqrt(mean_squared_error(y_test_raw, y_pred_raw))\n",
    "r2_raw = r2_score(y_test_raw, y_pred_raw)\n",
    "\n",
    "# Preprocessed data: Features and target\n",
    "X_preprocessed = df_preprocessed.drop(['Customer_ID', 'Transaction_Amount', 'Join_Date'], axis=1)\n",
    "y_preprocessed = df_preprocessed['Transaction_Amount']\n",
    "X_train_pre, X_test_pre, y_train_pre, y_test_pre = train_test_split(X_preprocessed, y_preprocessed, test_size=0.2, random_state=42)\n",
    "model_preprocessed = RandomForestRegressor(random_state=42)\n",
    "model_preprocessed.fit(X_train_pre, y_train_pre)\n",
    "y_pred_pre = model_preprocessed.predict(X_test_pre)\n",
    "\n",
    "# Metrics for preprocessed data\n",
    "rmse_preprocessed = np.sqrt(mean_squared_error(y_test_pre, y_pred_pre))\n",
    "r2_preprocessed = r2_score(y_test_pre, y_pred_pre)\n",
    "\n",
    "# Print results\n",
    "print(f\"RMSE on Raw Data: {rmse_raw}\")\n",
    "print(f\"R-squared on Raw Data: {r2_raw}\")\n",
    "print(f\"RMSE on Preprocessed Data: {rmse_preprocessed}\")\n",
    "print(f\"R-squared on Preprocessed Data: {r2_preprocessed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52351e4e-323b-4b44-8ea8-0a32e6b7a5e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'st' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Streamlit Dashboard\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mst\u001b[49m\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImpact of Preprocessing on Model Performance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Display Metrics\u001b[39;00m\n\u001b[0;32m      5\u001b[0m st\u001b[38;5;241m.\u001b[39mheader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Performance Comparison\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'st' is not defined"
     ]
    }
   ],
   "source": [
    "# Streamlit Dashboard\n",
    "st.title(\"Impact of Preprocessing on Model Performance\")\n",
    "\n",
    "# Display Metrics\n",
    "st.header(\"Model Performance Comparison\")\n",
    "st.write(f\"RMSE on Raw Data: {rmse_raw}\")\n",
    "st.write(f\"R-squared on Raw Data: {r2_raw}\")\n",
    "st.write(f\"RMSE on Preprocessed Data: {rmse_preprocessed}\")\n",
    "st.write(f\"R-squared on Preprocessed Data: {r2_preprocessed}\")\n",
    "\n",
    "# RMSE and R-squared Bar Chart\n",
    "st.header(\"Performance Metrics Comparison\")\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# RMSE Bar Chart\n",
    "ax[0].bar(['Raw Data', 'Preprocessed Data'], [rmse_raw, rmse_preprocessed], color=['red', 'green'])\n",
    "ax[0].set_title(\"RMSE Comparison\")\n",
    "ax[0].set_ylabel(\"RMSE\")\n",
    "\n",
    "# R-squared Bar Chart\n",
    "ax[1].bar(['Raw Data', 'Preprocessed Data'], [r2_raw, r2_preprocessed], color=['blue', 'orange'])\n",
    "ax[1].set_title(\"R-squared Comparison\")\n",
    "ax[1].set_ylabel(\"R-squared\")\n",
    "\n",
    "st.pyplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f621fc4-2c50-4367-8bca-e766e2aedfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
